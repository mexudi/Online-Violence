# Online-Violence

## Project Background

According to recent studies, cyberbullying is a growing concern in Morocco, particularly among young people. Many children and adolescents are experiencing online harassment, primarily on social media platforms such as Facebook, Instagram, and Snapchat. This is particularly alarming for vulnerable age groups, such as 10-13 year olds, who are already at risk of being victims of bullying. While some efforts have been made to address the issue, more needs to be done to protect children and provide them with the necessary resources and support to prevent and cope with cyberbullying. Parents, educators, and policymakers all have a role to play in promoting safe and responsible use of technology, educating young people on how to report cyberbullying incidents, and providing counseling and other support services to those who have been affected. 

To remedy this problem, we will be creating an NLP classifier to detect whether an online post is harmful to children.

## Problem Statment

The project's goal is to reduce the exploitation and abuse of children online, which has seen a drastic increase in recent years. Child sexual abuse materials (CSAM) have increased by an alarming 15,000% from 2005 to 2020, and the National Center for Missing and Exploited Children received a record-breaking 29.3 million reports of CSAM in 2021. Adults who have a sexual interest in children or intend to harm them often use online grooming to establish contact with them. Grooming is a complex and multidimensional process, where an adult seeks to engage a child in a seemingly voluntary interaction with the intention of sexually abusing them. Research suggests that children who are targeted by online grooming may not recognize the danger until it's too late, making it important to educate and raise awareness among children about the risks of online grooming and provide them with the necessary resources and support to protect themselves.

## Related Work

In 2020, Save the Children US collaborated with Omdena to address online violence. The most promising of the many solutions that came out of the sprint was a classifier algorithm that used Natural Language Processing to identify online grooming in conjunction with a chatbot that might alert the kids that they could be interacting with a groomer. Three engineers who were involved in the first project's development have since continued to improve the technology. The core team now hopes to extend the effort to develop a largescale, industry-useable solution. For this project, I will use the work that was done by Save the Children US and Omdena as a reference to conduct this project.

## Domain Resreach

At this early stage, different classes of hate were identified. Five among the most important classes of hate were defined as followed:

**Sexism:** Sexism: Refers to acts of violence that: 1) occur or linger in cyberspace; 2) are sexist, or sexual in nature; and 3) who reiterates dominant gender norms targeting girls and boys (tarnishing the former’s reputation and threatening the latter’s masculinity);

***Racism:*** Cyber racism is most commonly defined as racism which occurs in the cyber world. This includes racism which occurs on the internet such as racist websites, images, blogs, videos, and online comments as well as racist comments, images or language in text messages, emails or on social networking sites. It can be defined more broadly as any use of information and communication technologies to transmit racist attitudes and behaviour including the transfer of racially offensive content that is intended to cause harm or distress to another person [4];

***Homophobia:*** Sexual minorities often make greater use of the internet to look for specific socialization environments in which they can meet other people with the same orientation or can avoid face-to-face social rejection and homophobic bullying. Paradoxically, this greater use of the internet to escape offline discrimination could lead to greater exposure to OSVR (Online Sexual Victimization and Risks). The internet is an environment that reproduces societal prejudices, so it is reasonable to think that homophobia and discrimination will also be present online, causing higher rates of OSVR among sexual minorities. In turn, the higher rate of OSVR could partially explain the higher rate of negative mental health outcomes found among sexual minorities [5];


